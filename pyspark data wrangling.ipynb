{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modules imported\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init('D:\\spark-2.3.3-bin-hadoop2.7')\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "print('modules imported')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "app name build\n"
     ]
    }
   ],
   "source": [
    "spark= SparkSession.builder.appName('data_wrangling').getOrCreate()\n",
    "print('app name build')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------+------------+------------+-------+---------+-----+----------+----------+----------+-----------+------------+----+------+\n",
      "|_c0|               Date|AveragePrice|Total Volume|   4046|     4225| 4770|Total Bags|Small Bags|Large Bags|XLarge Bags|        type|year|region|\n",
      "+---+-------------------+------------+------------+-------+---------+-----+----------+----------+----------+-----------+------------+----+------+\n",
      "|  0|2015-12-27 00:00:00|        1.33|    64236.62|1036.74| 54454.85|48.16|   8696.87|   8603.62|     93.25|        0.0|conventional|2015|Albany|\n",
      "|  1|2015-12-20 00:00:00|        1.35|    54876.98| 674.28| 44638.81|58.33|   9505.56|   9408.07|     97.49|        0.0|conventional|2015|Albany|\n",
      "|  2|2015-12-13 00:00:00|        0.93|   118220.22|  794.7|109149.67|130.5|   8145.35|   8042.21|    103.14|        0.0|conventional|2015|Albany|\n",
      "|  3|2015-12-06 00:00:00|        1.08|    78992.15| 1132.0| 71976.41|72.58|   5811.16|    5677.4|    133.76|        0.0|conventional|2015|Albany|\n",
      "|  4|2015-11-29 00:00:00|        1.28|     51039.6| 941.48| 43838.39|75.78|   6183.95|   5986.26|    197.69|        0.0|conventional|2015|Albany|\n",
      "|  5|2015-11-22 00:00:00|        1.26|    55979.78|1184.27| 48067.99|43.61|   6683.91|   6556.47|    127.44|        0.0|conventional|2015|Albany|\n",
      "|  6|2015-11-15 00:00:00|        0.99|    83453.76|1368.92| 73672.72|93.26|   8318.86|   8196.81|    122.05|        0.0|conventional|2015|Albany|\n",
      "|  7|2015-11-08 00:00:00|        0.98|   109428.33| 703.75|101815.36| 80.0|   6829.22|   6266.85|    562.37|        0.0|conventional|2015|Albany|\n",
      "|  8|2015-11-01 00:00:00|        1.02|    99811.42|1022.15| 87315.57|85.34|  11388.36|  11104.53|    283.83|        0.0|conventional|2015|Albany|\n",
      "|  9|2015-10-25 00:00:00|        1.07|    74338.76|  842.4| 64757.44|113.0|   8625.92|   8061.47|    564.45|        0.0|conventional|2015|Albany|\n",
      "+---+-------------------+------------+------------+-------+---------+-----+----------+----------+----------+-----------+------------+----+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "avacado_df=spark.read.csv(r\"D:\\python coding\\Pyspark_BigData_study\\Data Wrangling\\avocado.csv\",\n",
    "                         inferSchema=True,header=True)\n",
    "avacado_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows 18249\n"
     ]
    }
   ],
   "source": [
    "#count rows\n",
    "print('number of rows '+str(avacado_df.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------+------------------+----------------+\n",
      "|summary|               _c0|      AveragePrice|      Total Volume|              4046|              4225|              4770|        Total Bags|        Small Bags|        Large Bags|       XLarge Bags|        type|              year|          region|\n",
      "+-------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------+------------------+----------------+\n",
      "|  count|             18249|             18249|             18249|             18249|             18249|             18249|             18249|             18249|             18249|             18249|       18249|             18249|           18249|\n",
      "|   mean|24.232231903117977|1.4059784097758825| 850644.0130089332|293008.42453066056|295154.56835607596|22839.735992657315|239639.20205983953|182194.68669571026| 54338.08814455636|3106.4265072058793|        null|2016.1478985149872|            null|\n",
      "| stddev| 15.48104475375712|0.4026765554955525|3453545.3553994684|1264989.0817627835|1204120.4011350533|107464.06843537069| 986242.3992164108| 746178.5149617895|243965.96454740898| 17692.89465191642|        null|0.9399384671420276|            null|\n",
      "|    min|                 0|              0.44|             84.56|               0.0|               0.0|               0.0|               0.0|               0.0|               0.0|               0.0|conventional|              2015|          Albany|\n",
      "|    max|                52|              3.25|     6.250564652E7|     2.274361617E7|     2.047057261E7|        2546439.11|     1.937313437E7|      1.33845868E7|        5719096.61|         551693.65|     organic|              2018|WestTexNewMexico|\n",
      "+-------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------+------------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "avacado_df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_c0',\n",
       " 'Date',\n",
       " 'AveragePrice',\n",
       " 'Total Volume',\n",
       " '4046',\n",
       " '4225',\n",
       " '4770',\n",
       " 'Total Bags',\n",
       " 'Small Bags',\n",
       " 'Large Bags',\n",
       " 'XLarge Bags',\n",
       " 'type',\n",
       " 'year',\n",
       " 'region']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avacado_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+\n",
      "|Total Volume|AveragePrice|\n",
      "+------------+------------+\n",
      "|    64236.62|        1.33|\n",
      "|    54876.98|        1.35|\n",
      "|   118220.22|        0.93|\n",
      "|    78992.15|        1.08|\n",
      "|     51039.6|        1.28|\n",
      "|    55979.78|        1.26|\n",
      "|    83453.76|        0.99|\n",
      "|   109428.33|        0.98|\n",
      "|    99811.42|        1.02|\n",
      "|    74338.76|        1.07|\n",
      "|    84843.44|        1.12|\n",
      "|    64489.17|        1.28|\n",
      "|     61007.1|        1.31|\n",
      "|   106803.39|        0.99|\n",
      "|    69759.01|        1.33|\n",
      "|    76111.27|        1.28|\n",
      "|    99172.96|        1.11|\n",
      "|   105693.84|        1.07|\n",
      "|    79992.09|        1.34|\n",
      "|    80043.78|        1.33|\n",
      "+------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#create subset of the dataframe\n",
    "#selecting two columns from total columns\n",
    "#method 1\n",
    "columns_to_subset=['Total Volume','AveragePrice']\n",
    "df_1=avacado_df.select(*[columns_to_subset])\n",
    "df_1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+\n",
      "|Total Volume|AveragePrice|\n",
      "+------------+------------+\n",
      "|    64236.62|        1.33|\n",
      "|    54876.98|        1.35|\n",
      "|   118220.22|        0.93|\n",
      "|    78992.15|        1.08|\n",
      "|     51039.6|        1.28|\n",
      "|    55979.78|        1.26|\n",
      "|    83453.76|        0.99|\n",
      "|   109428.33|        0.98|\n",
      "|    99811.42|        1.02|\n",
      "|    74338.76|        1.07|\n",
      "|    84843.44|        1.12|\n",
      "|    64489.17|        1.28|\n",
      "|     61007.1|        1.31|\n",
      "|   106803.39|        0.99|\n",
      "|    69759.01|        1.33|\n",
      "|    76111.27|        1.28|\n",
      "|    99172.96|        1.11|\n",
      "|   105693.84|        1.07|\n",
      "|    79992.09|        1.34|\n",
      "|    80043.78|        1.33|\n",
      "+------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#method 2 select columns for subset \n",
    "df_2=avacado_df.select('Total Volume','AveragePrice')\n",
    "df_2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+\n",
      "|Total Volume|AveragePrice|\n",
      "+------------+------------+\n",
      "|    64236.62|        1.33|\n",
      "|    54876.98|        1.35|\n",
      "|   118220.22|        0.93|\n",
      "|    78992.15|        1.08|\n",
      "|     51039.6|        1.28|\n",
      "|    55979.78|        1.26|\n",
      "|    83453.76|        0.99|\n",
      "|   109428.33|        0.98|\n",
      "|    99811.42|        1.02|\n",
      "|    74338.76|        1.07|\n",
      "|    84843.44|        1.12|\n",
      "|    64489.17|        1.28|\n",
      "|     61007.1|        1.31|\n",
      "|   106803.39|        0.99|\n",
      "|    69759.01|        1.33|\n",
      "|    76111.27|        1.28|\n",
      "|    99172.96|        1.11|\n",
      "|   105693.84|        1.07|\n",
      "|    79992.09|        1.34|\n",
      "|    80043.78|        1.33|\n",
      "+------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#method 3 to create subset of data\n",
    "#using indexes\n",
    "df_3=avacado_df.select(avacado_df[3],avacado_df[2])\n",
    "df_3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#count null values in a column\n",
    "avacado_df.where(avacado_df['Total Volume'].isNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|        type|count|\n",
      "+------------+-----+\n",
      "|     organic| 9123|\n",
      "|conventional| 9126|\n",
      "+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#group by on values\n",
    "avacado_df.groupby(avacado_df['type']).count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+\n",
      "| type_region|Albany|\n",
      "+------------+------+\n",
      "|conventional|   169|\n",
      "|     organic|   169|\n",
      "+------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#crosstab values\n",
    "avacado_df.where(avacado_df['region']=='Albany').crosstab('type','region').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------+------------+------------+-------+---------+-----+----------+----------+----------+-----------+------------+----+------+\n",
      "|_c0|               Date|AveragePrice|Total Volume|   4046|     4225| 4770|Total Bags|Small Bags|Large Bags|XLarge Bags|        type|year|region|\n",
      "+---+-------------------+------------+------------+-------+---------+-----+----------+----------+----------+-----------+------------+----+------+\n",
      "|  0|2015-12-27 00:00:00|        1.33|    64236.62|1036.74| 54454.85|48.16|   8696.87|   8603.62|     93.25|        0.0|conventional|2015|Albany|\n",
      "|  1|2015-12-20 00:00:00|        1.35|    54876.98| 674.28| 44638.81|58.33|   9505.56|   9408.07|     97.49|        0.0|conventional|2015|Albany|\n",
      "|  2|2015-12-13 00:00:00|        0.93|   118220.22|  794.7|109149.67|130.5|   8145.35|   8042.21|    103.14|        0.0|conventional|2015|Albany|\n",
      "|  3|2015-12-06 00:00:00|        1.08|    78992.15| 1132.0| 71976.41|72.58|   5811.16|    5677.4|    133.76|        0.0|conventional|2015|Albany|\n",
      "|  4|2015-11-29 00:00:00|        1.28|     51039.6| 941.48| 43838.39|75.78|   6183.95|   5986.26|    197.69|        0.0|conventional|2015|Albany|\n",
      "|  5|2015-11-22 00:00:00|        1.26|    55979.78|1184.27| 48067.99|43.61|   6683.91|   6556.47|    127.44|        0.0|conventional|2015|Albany|\n",
      "|  6|2015-11-15 00:00:00|        0.99|    83453.76|1368.92| 73672.72|93.26|   8318.86|   8196.81|    122.05|        0.0|conventional|2015|Albany|\n",
      "|  7|2015-11-08 00:00:00|        0.98|   109428.33| 703.75|101815.36| 80.0|   6829.22|   6266.85|    562.37|        0.0|conventional|2015|Albany|\n",
      "|  8|2015-11-01 00:00:00|        1.02|    99811.42|1022.15| 87315.57|85.34|  11388.36|  11104.53|    283.83|        0.0|conventional|2015|Albany|\n",
      "|  9|2015-10-25 00:00:00|        1.07|    74338.76|  842.4| 64757.44|113.0|   8625.92|   8061.47|    564.45|        0.0|conventional|2015|Albany|\n",
      "+---+-------------------+------------+------------+-------+---------+-----+----------+----------+----------+-----------+------------+----+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#filter condition using where clause\n",
    "avacado_df.where(avacado_df['region']=='Albany').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "avacado_new=avacado_df.withColumn('Total Volume',avacado_df['Total Volume'].cast('float'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- Date: timestamp (nullable = true)\n",
      " |-- AveragePrice: double (nullable = true)\n",
      " |-- Total Volume: double (nullable = true)\n",
      " |-- 4046: double (nullable = true)\n",
      " |-- 4225: double (nullable = true)\n",
      " |-- 4770: double (nullable = true)\n",
      " |-- Total Bags: double (nullable = true)\n",
      " |-- Small Bags: double (nullable = true)\n",
      " |-- Large Bags: double (nullable = true)\n",
      " |-- XLarge Bags: double (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- region: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "avacado_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- Date: timestamp (nullable = true)\n",
      " |-- AveragePrice: double (nullable = true)\n",
      " |-- Total Volume: float (nullable = true)\n",
      " |-- 4046: double (nullable = true)\n",
      " |-- 4225: double (nullable = true)\n",
      " |-- 4770: double (nullable = true)\n",
      " |-- Total Bags: double (nullable = true)\n",
      " |-- Small Bags: double (nullable = true)\n",
      " |-- Large Bags: double (nullable = true)\n",
      " |-- XLarge Bags: double (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- region: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avacado_new.printSchema()\n",
    "#datatype of total volume changed to float\n",
    "type(avacado_new) #datatype is dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|            region|\n",
      "+------------------+\n",
      "|     PhoenixTucson|\n",
      "|       GrandRapids|\n",
      "|     SouthCarolina|\n",
      "|           TotalUS|\n",
      "|  WestTexNewMexico|\n",
      "|        Louisville|\n",
      "|      Philadelphia|\n",
      "|        Sacramento|\n",
      "|     DallasFtWorth|\n",
      "|      Indianapolis|\n",
      "|          LasVegas|\n",
      "|         Nashville|\n",
      "|        GreatLakes|\n",
      "|           Detroit|\n",
      "|            Albany|\n",
      "|          Portland|\n",
      "|  CincinnatiDayton|\n",
      "|          SanDiego|\n",
      "|             Boise|\n",
      "|HarrisburgScranton|\n",
      "+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#find distinct values of region column\n",
    "avacado_df.select('region').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----+\n",
      "|            region|count|\n",
      "+------------------+-----+\n",
      "|     PhoenixTucson|  338|\n",
      "|       GrandRapids|  338|\n",
      "|     SouthCarolina|  338|\n",
      "|           TotalUS|  338|\n",
      "|  WestTexNewMexico|  335|\n",
      "|        Louisville|  338|\n",
      "|      Philadelphia|  338|\n",
      "|        Sacramento|  338|\n",
      "|     DallasFtWorth|  338|\n",
      "|      Indianapolis|  338|\n",
      "|          LasVegas|  338|\n",
      "|         Nashville|  338|\n",
      "|        GreatLakes|  338|\n",
      "|           Detroit|  338|\n",
      "|            Albany|  338|\n",
      "|          Portland|  338|\n",
      "|  CincinnatiDayton|  338|\n",
      "|          SanDiego|  338|\n",
      "|             Boise|  338|\n",
      "|HarrisburgScranton|  338|\n",
      "+------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NoneType"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using groupby and count of region values\n",
    "region_df=avacado_df.groupby('region').count().show()\n",
    "type(region_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169\n"
     ]
    }
   ],
   "source": [
    "#filter data \n",
    "filter_count=avacado_df.filter((avacado_df['type']=='organic') & (avacado_df['region']=='Albany')).count()\n",
    "#print('filtered data '+ str(filter_count))\n",
    "type(avacado_df) #datatype is dataframe\n",
    "type(filter_count) #datatype is int so we can tuse show() mehtod for output\n",
    "#count is an action\n",
    "print(filter_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_c0',\n",
       " 'Date',\n",
       " 'AveragePrice',\n",
       " 'Total_Volume',\n",
       " '4046',\n",
       " '4225',\n",
       " '4770',\n",
       " 'Total_Bags',\n",
       " 'Small_Bags',\n",
       " 'Large_Bags',\n",
       " 'XLarge_Bags',\n",
       " 'type',\n",
       " 'year',\n",
       " 'region']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rename columns\n",
    "avacado_df=avacado_df.withColumnRenamed('Total Volume','Total_Volume').withColumnRenamed('Total Bags','Total_Bags').withColumnRenamed('Small bags','Small_Bags').withColumnRenamed('Large Bags','Large_Bags')\n",
    "avacado_df=avacado_df.withColumnRenamed('XLarge Bags','XLarge_Bags')\n",
    "avacado_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------+----------+------------------+\n",
      "|_c0|Total_Volume|Total_Bags|    Avg_volume_bag|\n",
      "+---+------------+----------+------------------+\n",
      "|  0|    64236.62|   8696.87| 7.386176865929926|\n",
      "|  1|    54876.98|   9505.56| 5.773145401217814|\n",
      "|  2|   118220.22|   8145.35|14.513829362765259|\n",
      "|  3|    78992.15|   5811.16|13.593181051631687|\n",
      "|  4|     51039.6|   6183.95| 8.253559618043484|\n",
      "|  5|    55979.78|   6683.91| 8.375304275491441|\n",
      "|  6|    83453.76|   8318.86|10.031874559735346|\n",
      "|  7|   109428.33|   6829.22|16.023547345084797|\n",
      "|  8|    99811.42|  11388.36| 8.764336568215265|\n",
      "|  9|    74338.76|   8625.92| 8.618067406143345|\n",
      "| 10|    84843.44|   8205.66| 10.33962411311217|\n",
      "| 11|    64489.17|   10123.9| 6.369992789340077|\n",
      "| 12|     61007.1|   8756.75| 6.966865560853056|\n",
      "| 13|   106803.39|   6034.46|17.698914235905118|\n",
      "| 14|    69759.01|   9267.36| 7.527387519207195|\n",
      "| 15|    76111.27|   9286.68| 8.195745950113496|\n",
      "| 16|    99172.96|    7990.1|12.411979825033479|\n",
      "| 17|   105693.84|  10306.73|10.254837373250293|\n",
      "| 18|    79992.09|  10880.36| 7.351970890669058|\n",
      "| 19|    80043.78|  10443.22| 7.664664729843861|\n",
      "+---+------------+----------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['_c0', 'Total_Volume', 'Total_Bags', 'Avg_volume_bag']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create new column\n",
    "df_avg_bags=avacado_df.select('_c0','Total_Volume','Total_Bags').withColumn('Avg_volume_bag',avacado_df['Total_Volume']/avacado_df['Total_Bags'])\n",
    "df_avg_bags.show()\n",
    "df_avg_bags.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------+----------+------------------+-------+\n",
      "|_c0|Total_Volume|Total_Bags|    Avg_volume_bag|bag_per|\n",
      "+---+------------+----------+------------------+-------+\n",
      "|  0|    64236.62|   8696.87| 7.386176865929926|   null|\n",
      "|  1|    54876.98|   9505.56| 5.773145401217814|   null|\n",
      "|  2|   118220.22|   8145.35|14.513829362765259|   null|\n",
      "|  3|    78992.15|   5811.16|13.593181051631687|   null|\n",
      "|  4|     51039.6|   6183.95| 8.253559618043484|   null|\n",
      "|  5|    55979.78|   6683.91| 8.375304275491441|   null|\n",
      "|  6|    83453.76|   8318.86|10.031874559735346|   null|\n",
      "|  7|   109428.33|   6829.22|16.023547345084797|   null|\n",
      "|  8|    99811.42|  11388.36| 8.764336568215265|   null|\n",
      "|  9|    74338.76|   8625.92| 8.618067406143345|   null|\n",
      "| 10|    84843.44|   8205.66| 10.33962411311217|   null|\n",
      "| 11|    64489.17|   10123.9| 6.369992789340077|   null|\n",
      "| 12|     61007.1|   8756.75| 6.966865560853056|   null|\n",
      "| 13|   106803.39|   6034.46|17.698914235905118|   null|\n",
      "| 14|    69759.01|   9267.36| 7.527387519207195|   null|\n",
      "| 15|    76111.27|   9286.68| 8.195745950113496|   null|\n",
      "| 16|    99172.96|    7990.1|12.411979825033479|   null|\n",
      "| 17|   105693.84|  10306.73|10.254837373250293|   null|\n",
      "| 18|    79992.09|  10880.36| 7.351970890669058|   null|\n",
      "| 19|    80043.78|  10443.22| 7.664664729843861|   null|\n",
      "+---+------------+----------+------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#create a new column with null value\n",
    "#lit is use to create a new columns with a literal or a constant value\n",
    "#in our example we have uses lit to create a column with default Null value\n",
    "#cast to define datatype of the column\n",
    "from pyspark.sql.functions import lit,concat\n",
    "from pyspark.sql.types import StringType\n",
    "df_new_col=df_avg_bags.withColumn('bag_per',lit(None).cast(StringType()))\n",
    "df_new_col.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------+----------+------------------+------------------+\n",
      "|_c0|Total_Volume|Total_Bags|    Avg_volume_bag|           bag_per|\n",
      "+---+------------+----------+------------------+------------------+\n",
      "|  0|    64236.62|   8696.87| 7.386176865929926| 738.6176865929926|\n",
      "|  1|    54876.98|   9505.56| 5.773145401217814| 577.3145401217814|\n",
      "|  2|   118220.22|   8145.35|14.513829362765259| 1451.382936276526|\n",
      "|  3|    78992.15|   5811.16|13.593181051631687|1359.3181051631686|\n",
      "|  4|     51039.6|   6183.95| 8.253559618043484| 825.3559618043485|\n",
      "|  5|    55979.78|   6683.91| 8.375304275491441| 837.5304275491441|\n",
      "|  6|    83453.76|   8318.86|10.031874559735346|1003.1874559735346|\n",
      "|  7|   109428.33|   6829.22|16.023547345084797|1602.3547345084796|\n",
      "|  8|    99811.42|  11388.36| 8.764336568215265| 876.4336568215265|\n",
      "|  9|    74338.76|   8625.92| 8.618067406143345| 861.8067406143344|\n",
      "| 10|    84843.44|   8205.66| 10.33962411311217| 1033.962411311217|\n",
      "| 11|    64489.17|   10123.9| 6.369992789340077| 636.9992789340076|\n",
      "| 12|     61007.1|   8756.75| 6.966865560853056| 696.6865560853056|\n",
      "| 13|   106803.39|   6034.46|17.698914235905118|1769.8914235905117|\n",
      "| 14|    69759.01|   9267.36| 7.527387519207195| 752.7387519207194|\n",
      "| 15|    76111.27|   9286.68| 8.195745950113496| 819.5745950113496|\n",
      "| 16|    99172.96|    7990.1|12.411979825033479| 1241.197982503348|\n",
      "| 17|   105693.84|  10306.73|10.254837373250293|1025.4837373250293|\n",
      "| 18|    79992.09|  10880.36| 7.351970890669058| 735.1970890669058|\n",
      "| 19|    80043.78|  10443.22| 7.664664729843861| 766.4664729843861|\n",
      "+---+------------+----------+------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#adding values for bag_per column\n",
    "bag_per_df=df_new_col.select(df_new_col['_c0'],df_new_col['Total_Volume'],df_new_col['Total_Bags'],df_new_col['Avg_volume_bag'],concat((df_new_col['Total_Volume']/df_new_col['Total_Bags'])*100).alias('bag_per'))\n",
    "bag_per_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#user defined functions on dataframes\n",
    "def tot_vol(Total_Volume,AveragePrice):\n",
    "    if Total_Volume<42000:\n",
    "        volume_category='Small'\n",
    "    elif Total_Volume>42000 and Total_Volume<850644:\n",
    "        volume_category='Medium'\n",
    "    else:\n",
    "        volume_category='High'\n",
    "    if AveragePrice<1.25:\n",
    "        Price_Category='Low'\n",
    "    elif AveragePrice>1.25 and AveragePrice<1.45:\n",
    "        Price_Category='Medium'\n",
    "    else:\n",
    "        Price_Category='High'\n",
    "    return volume_category,Price_Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Small', 'Medium')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot_vol(41000,1.34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------+------------+----------------+\n",
      "|_c0|Total_Volume|AveragePrice|          newcat|\n",
      "+---+------------+------------+----------------+\n",
      "|  0|    64236.62|        1.33|[Medium, Medium]|\n",
      "|  1|    54876.98|        1.35|[Medium, Medium]|\n",
      "|  2|   118220.22|        0.93|   [Medium, Low]|\n",
      "|  3|    78992.15|        1.08|   [Medium, Low]|\n",
      "|  4|     51039.6|        1.28|[Medium, Medium]|\n",
      "|  5|    55979.78|        1.26|[Medium, Medium]|\n",
      "|  6|    83453.76|        0.99|   [Medium, Low]|\n",
      "|  7|   109428.33|        0.98|   [Medium, Low]|\n",
      "|  8|    99811.42|        1.02|   [Medium, Low]|\n",
      "|  9|    74338.76|        1.07|   [Medium, Low]|\n",
      "| 10|    84843.44|        1.12|   [Medium, Low]|\n",
      "| 11|    64489.17|        1.28|[Medium, Medium]|\n",
      "| 12|     61007.1|        1.31|[Medium, Medium]|\n",
      "| 13|   106803.39|        0.99|   [Medium, Low]|\n",
      "| 14|    69759.01|        1.33|[Medium, Medium]|\n",
      "| 15|    76111.27|        1.28|[Medium, Medium]|\n",
      "| 16|    99172.96|        1.11|   [Medium, Low]|\n",
      "| 17|   105693.84|        1.07|   [Medium, Low]|\n",
      "| 18|    79992.09|        1.34|[Medium, Medium]|\n",
      "| 19|    80043.78|        1.33|[Medium, Medium]|\n",
      "+---+------------+------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#now we will apply this userf defined function to the dataframe\n",
    "#user defined function are termed as UDFs in spark\n",
    "from pyspark.sql.functions import udf,split\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, ArrayType\n",
    "avacado_df.columns\n",
    "#df_udf=avacado_df.select('_c0','Date','AveragePrice','Total_Volume')\n",
    "#we will applu udf to new dataframe df_udf\n",
    "\n",
    "udfb=udf(tot_vol,StructType([\n",
    "    StructField('volume_category',StringType(),nullable=True),\n",
    "    StructField('Price_Category',StringType(),nullable=True)\n",
    "]))\n",
    "\n",
    "df2=avacado_df.select('_c0','Total_Volume','AveragePrice').withColumn(\"newcat\",udfb(\"Total_Volume\",\"AveragePrice\"))\n",
    "df2.show()\n",
    "#both new values are returned into a a single colmn newcat as array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------+------------+---------------+--------------+\n",
      "|_c0|Total_Volume|AveragePrice|volume_category|price_category|\n",
      "+---+------------+------------+---------------+--------------+\n",
      "|  0|    64236.62|        1.33|         Medium|        Medium|\n",
      "|  1|    54876.98|        1.35|         Medium|        Medium|\n",
      "|  2|   118220.22|        0.93|         Medium|           Low|\n",
      "|  3|    78992.15|        1.08|         Medium|           Low|\n",
      "|  4|     51039.6|        1.28|         Medium|        Medium|\n",
      "|  5|    55979.78|        1.26|         Medium|        Medium|\n",
      "|  6|    83453.76|        0.99|         Medium|           Low|\n",
      "|  7|   109428.33|        0.98|         Medium|           Low|\n",
      "|  8|    99811.42|        1.02|         Medium|           Low|\n",
      "|  9|    74338.76|        1.07|         Medium|           Low|\n",
      "| 10|    84843.44|        1.12|         Medium|           Low|\n",
      "| 11|    64489.17|        1.28|         Medium|        Medium|\n",
      "| 12|     61007.1|        1.31|         Medium|        Medium|\n",
      "| 13|   106803.39|        0.99|         Medium|           Low|\n",
      "| 14|    69759.01|        1.33|         Medium|        Medium|\n",
      "| 15|    76111.27|        1.28|         Medium|        Medium|\n",
      "| 16|    99172.96|        1.11|         Medium|           Low|\n",
      "| 17|   105693.84|        1.07|         Medium|           Low|\n",
      "| 18|    79992.09|        1.34|         Medium|        Medium|\n",
      "| 19|    80043.78|        1.33|         Medium|        Medium|\n",
      "+---+------------+------------+---------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3=df2.select('_c0','Total_Volume','AveragePrice','newcat').withColumn('volume_category',df2.newcat.getItem('volume_category')).withColumn('price_category',df2.newcat.getItem('Price_Category'))\n",
    "#df3.show()\n",
    "df_final=df3.drop('newcat')\n",
    "df_final.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------+------------+----------------------+---------------------+\n",
      "|_c0|Total_Volume|AveragePrice|upper(volume_category)|upper(price_category)|\n",
      "+---+------------+------------+----------------------+---------------------+\n",
      "|  0|    64236.62|        1.33|                MEDIUM|               MEDIUM|\n",
      "|  1|    54876.98|        1.35|                MEDIUM|               MEDIUM|\n",
      "|  2|   118220.22|        0.93|                MEDIUM|                  LOW|\n",
      "|  3|    78992.15|        1.08|                MEDIUM|                  LOW|\n",
      "|  4|     51039.6|        1.28|                MEDIUM|               MEDIUM|\n",
      "|  5|    55979.78|        1.26|                MEDIUM|               MEDIUM|\n",
      "|  6|    83453.76|        0.99|                MEDIUM|                  LOW|\n",
      "|  7|   109428.33|        0.98|                MEDIUM|                  LOW|\n",
      "|  8|    99811.42|        1.02|                MEDIUM|                  LOW|\n",
      "|  9|    74338.76|        1.07|                MEDIUM|                  LOW|\n",
      "| 10|    84843.44|        1.12|                MEDIUM|                  LOW|\n",
      "| 11|    64489.17|        1.28|                MEDIUM|               MEDIUM|\n",
      "| 12|     61007.1|        1.31|                MEDIUM|               MEDIUM|\n",
      "| 13|   106803.39|        0.99|                MEDIUM|                  LOW|\n",
      "| 14|    69759.01|        1.33|                MEDIUM|               MEDIUM|\n",
      "| 15|    76111.27|        1.28|                MEDIUM|               MEDIUM|\n",
      "| 16|    99172.96|        1.11|                MEDIUM|                  LOW|\n",
      "| 17|   105693.84|        1.07|                MEDIUM|                  LOW|\n",
      "| 18|    79992.09|        1.34|                MEDIUM|               MEDIUM|\n",
      "| 19|    80043.78|        1.33|                MEDIUM|               MEDIUM|\n",
      "+---+------------+------------+----------------------+---------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#upper casing newly added columns\n",
    "from pyspark.sql.functions import concat,trim,upper\n",
    "df_final=df_final.select('_c0','Total_Volume','AveragePrice',upper(df_final['volume_category']),upper(df_final['price_category']))\n",
    "df_final.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_c0', 'Total_Volume', 'AveragePrice', 'volume_category', 'price_category']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.columns\n",
    "df_final=df_final.withColumnRenamed('upper(volume_category)','volume_category').withColumnRenamed('upper(price_category)','price_category')\n",
    "df_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------+------------+---------------+--------------+\n",
      "|_c0|Total_Volume|AveragePrice|volume_category|price_category|\n",
      "+---+------------+------------+---------------+--------------+\n",
      "|  0|    64236.62|        1.33|            Med|        MEDIUM|\n",
      "|  1|    54876.98|        1.35|            Med|        MEDIUM|\n",
      "|  2|   118220.22|        0.93|            Med|           LOW|\n",
      "|  3|    78992.15|        1.08|            Med|           LOW|\n",
      "|  4|     51039.6|        1.28|            Med|        MEDIUM|\n",
      "|  5|    55979.78|        1.26|            Med|        MEDIUM|\n",
      "|  6|    83453.76|        0.99|            Med|           LOW|\n",
      "|  7|   109428.33|        0.98|            Med|           LOW|\n",
      "|  8|    99811.42|        1.02|            Med|           LOW|\n",
      "|  9|    74338.76|        1.07|            Med|           LOW|\n",
      "| 10|    84843.44|        1.12|            Med|           LOW|\n",
      "| 11|    64489.17|        1.28|            Med|        MEDIUM|\n",
      "| 12|     61007.1|        1.31|            Med|        MEDIUM|\n",
      "| 13|   106803.39|        0.99|            Med|           LOW|\n",
      "| 14|    69759.01|        1.33|            Med|        MEDIUM|\n",
      "| 15|    76111.27|        1.28|            Med|        MEDIUM|\n",
      "| 16|    99172.96|        1.11|            Med|           LOW|\n",
      "| 17|   105693.84|        1.07|            Med|           LOW|\n",
      "| 18|    79992.09|        1.34|            Med|        MEDIUM|\n",
      "| 19|    80043.78|        1.33|            Med|        MEDIUM|\n",
      "+---+------------+------------+---------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#update a column value\n",
    "#using when clause\n",
    "#orks as case statemen\n",
    "from pyspark.sql.functions import when\n",
    "df4=df_final.withColumn('volume_category',when (df_final['volume_category']=='MEDIUM','Med').\n",
    "                       when (df_final['volume_category']=='SMALL','SMALL').\n",
    "                      when (df_final['volume_category']=='HIGH','UP').otherwise(df_final['volume_category']))\n",
    "\n",
    "df4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'toDebugString'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-9ce67baed413>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf4\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoDebugString\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\spark-2.3.3-bin-hadoop2.7\\python\\pyspark\\sql\\dataframe.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1180\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1181\u001b[0m             raise AttributeError(\n\u001b[1;32m-> 1182\u001b[1;33m                 \"'%s' object has no attribute '%s'\" % (self.__class__.__name__, name))\n\u001b[0m\u001b[0;32m   1183\u001b[0m         \u001b[0mjc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1184\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mColumn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'toDebugString'"
     ]
    }
   ],
   "source": [
    "df4.toDebugString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
